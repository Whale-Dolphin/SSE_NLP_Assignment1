# Configuration file for the Transformer model training

# Model hyperparameters
embedding_size: 512
nhead: 8
nhid: 2048
nlayers: 6
vocab_size: 30000


batch_size: 32
epochs: 20
learning_rate: 0.0001

# Data paths
train_file: './data/train_data.pkl'
val_file: './data/val_data.pkl'

# Checkpoint path
checkpoint_path: './checkpoints/model_checkpoint'

# Logging and printing
log_interval: 100 

# Device configuration
use_cuda: True 
